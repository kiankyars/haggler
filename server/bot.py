#
# Copyright (c) 2024–2025, Daily
#
# SPDX-License-Identifier: BSD 2-Clause License
#

"""haggler - Pipecat Voice Agent.

This bot uses a realtime pipeline: Speech-to-Speech with integrated LLM

Generated by Pipecat CLI

Required AI services:
- Gemini_Live (Realtime Speech-to-Speech)

Run the bot using::
    uv run bot.py
"""


from pipecat.pipeline.runner import PipelineRunner
from pipecat.audio.vad.vad_analyzer import VADParams
from pipecat.processors.aggregators.llm_response_universal import LLMContextAggregatorPair, LLMUserAggregatorParams
from pipecat.processors.aggregators.llm_context import LLMContext
from pipecat.transports.smallwebrtc.connection import SmallWebRTCConnection
import os
from pipecat.transports.base_transport import BaseTransport
from pipecat.pipeline.pipeline import Pipeline
from pipecat.transports.smallwebrtc.transport import SmallWebRTCTransport
from dotenv import load_dotenv
from pipecat.runner.types import SmallWebRTCRunnerArguments
from pipecat.transports.base_transport import TransportParams
from pipecat.audio.vad.silero import SileroVADAnalyzer
from pipecat.pipeline.task import PipelineParams, PipelineTask
from loguru import logger
from pipecat.services.google.gemini_live.llm import GeminiLiveLLMService
from pipecat.runner.types import RunnerArguments
import asyncio
import weave
import redis
import uuid
import time

from google import genai

load_dotenv(override=True)

if os.getenv("WANDB_API_KEY"):
    # Use entity/project (e.g. factorio/haggler) so traces appear in the right W&B project
    project = os.getenv("WEAVE_PROJECT", "haggler")
    entity = os.getenv("WANDB_ENTITY")
    if entity and "/" not in project:
        project = f"{entity}/{project}"
    try:
        weave.init(project)
    except Exception as e:
        logger.warning(f"Weave init failed ({e}); running without tracing")

REDIS_TACTICS_KEY = "agent:tactics"
REDIS_WINNING_KEY = "agent:winning_tactics"
REDIS_FAILED_KEY = "agent:failed_tactics"
REDIS_SESSION_TACTICS_PREFIX = "session:"
REDIS_SESSION_TACTICS_SUFFIX = ":tactics"

BASE_REFUND = (
    "You are a customer on a voice call with customer support. You are seeking a refund. "
    "Use the tactics provided. Stay in character as the customer. You are calling them; they answer. "
    "As soon as the support agent grants the refund, end the call immediately—say a brief thanks and hang up. "
    "Do not prolong the conversation, ask follow-ups, or add lengthy goodbyes once the refund is granted."
)
BASE_NEGOTIATION = (
    "You are a customer on a voice call negotiating (e.g. a discount, booking, or deal). "
    "Use the tactics provided. Stay in character as the customer. You are calling them; they answer."
)


@weave.op()
def get_session_config(session_id: str | None = None) -> dict:
    """Fetch base system instruction and Redis tactics for Weave trace + agent use."""
    mode = os.getenv("HAGGLER_MODE", "refund").lower()
    base = BASE_REFUND if mode == "refund" else BASE_NEGOTIATION
    tactics: list[str] = []
    url = os.getenv("REDIS_URL")
    if url:
        r = redis.from_url(url)
        winning_raw = r.lrange(REDIS_WINNING_KEY, 0, -1)
        winning = [b.decode() if isinstance(b, bytes) else b for b in (winning_raw or [])]
        raw = r.lrange(REDIS_TACTICS_KEY, 0, -1)
        base_tactics = [b.decode() if isinstance(b, bytes) else b for b in (raw or [])]
        seen = set(winning)
        tactics = list(winning)
        for t in base_tactics:
            if t not in seen:
                tactics.append(t)
                seen.add(t)
        r.close()
    if tactics:
        base = f"{base}\n\nWinning tactics to use when appropriate:\n" + "\n".join(f"- {t}" for t in tactics)
    return {
        "system_instruction": base,
        "tactics_count": len(tactics),
        "tactics": tactics,
        "session_id": session_id,
        "mode": mode,
    }


@weave.op()
def log_session_end(
    session_id: str,
    config: dict,
    duration_seconds: float,
    outcome: str,
    transcript_length: int = 0,
    transcript_preview: str = "",
) -> dict:
    """Log session end and outcome score to Weave so evals/traces show success/failure."""
    score = 1.0 if outcome == "success" else 0.0
    # Return only fields not already in inputs (avoids duplicate columns in trace tables)
    return {
        "score": score,
        "tactics_count": config.get("tactics_count", 0),
        "mode": config.get("mode", "refund"),
    }


def _format_transcript(messages: list) -> str:
    lines = []
    for m in messages:
        role = m.get("role", "unknown")
        if role == "system":
            continue
        content = m.get("content")
        if content is None:
            continue
        if isinstance(content, list):
            parts = []
            for p in content:
                if isinstance(p, dict) and "text" in p:
                    parts.append(str(p["text"]).strip())
                elif isinstance(p, dict) and "type" in p and p.get("type") == "text":
                    parts.append(str(p.get("text", "")).strip())
                elif isinstance(p, str):
                    parts.append(p.strip())
            content = " ".join(p for p in parts if p) or None
        elif isinstance(content, str):
            content = content.strip() or None
        else:
            content = str(content).strip() or None
        if content:
            lines.append(f"{role}: {content}")
    return "\n".join(lines)


def _evaluate_outcome(transcript: str, mode: str) -> str:
    """Call LLM to classify outcome as success or failure. Sync, run in thread."""
    if not transcript.strip():
        return "failure"
    prompt = (
        f"You are evaluating a voice call. The customer is the 'assistant' in the transcript; 'user' is support/agent. "
        f"The customer was {'seeking a refund' if mode == 'refund' else 'negotiating (discount/booking/deal)'}. "
        f"Did the customer get what they wanted (refund granted, deal agreed, discount given, etc.)?\n\n"
        f"Transcript:\n{transcript}\n\n"
        f"Answer with exactly one word: success or failure."
    )
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        return "failure"
    try:
        client = genai.Client(api_key=api_key)
        model = os.getenv("GOOGLE_EVAL_MODEL", "gemini-2.0-flash")
        response = client.models.generate_content(model=model, contents=prompt)
        text = getattr(response, "text", None) or ""
        if not text and getattr(response, "candidates", None):
            c = response.candidates[0] if response.candidates else None
            if c and getattr(c, "content", None) and c.content.parts:
                text = getattr(c.content.parts[0], "text", "") or ""
        text = text.strip().lower()
        # Accept "success" anywhere (Gemini often says "The outcome is success." not just "success")
        return "success" if "success" in text else "failure"
    except Exception:
        return "failure"


def _suggest_new_tactic(transcript: str, mode: str) -> str:
    """Ask Gemini for one new tactic based on what worked in this successful call. Sync, run in thread."""
    if not transcript.strip():
        return ""
    goal = "refund" if mode == "refund" else "negotiation (discount/booking/deal)"
    prompt = (
        f"You are analyzing a successful voice call. In the transcript, the customer is the 'assistant', support is the 'user'. "
        f"The customer got what they wanted ({goal}). Based on what worked in this call, suggest exactly one new tactic "
        f"that could help in similar situations. Output only the tactic text, one clear sentence, no preamble or numbering."
    )
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        return ""
    client = genai.Client(api_key=api_key)
    model_name = os.getenv("GOOGLE_EVAL_MODEL", "gemini-2.0-flash")
    response = client.models.generate_content(
        model=model_name,
        contents=f"{prompt}\n\nTranscript:\n{transcript}",
    )
    text = getattr(response, "text", None) or ""
    if not text and getattr(response, "candidates", None):
        c = response.candidates[0] if response.candidates else None
        if c and getattr(c, "content", None) and c.content.parts:
            text = getattr(c.content.parts[0], "text", "") or ""
    return text.strip() if text else ""


def _merge_winning_tactics(url: str, session_id: str, tactics: list[str]) -> None:
    """Merge session tactics into agent:winning_tactics (self-improvement)."""
    r = redis.from_url(url)
    key = f"{REDIS_SESSION_TACTICS_PREFIX}{session_id}{REDIS_SESSION_TACTICS_SUFFIX}"
    raw = r.lrange(key, 0, -1)
    session_tactics = [b.decode() if isinstance(b, bytes) else b for b in (raw or [])]
    r.delete(key)
    existing = set(r.lrange(REDIS_WINNING_KEY, 0, -1) or [])
    existing_decoded = {e.decode() if isinstance(e, bytes) else e for e in existing}
    for t in session_tactics or tactics:
        if t not in existing_decoded:
            r.rpush(REDIS_WINNING_KEY, t)
            existing_decoded.add(t)
    r.close()




async def run_bot(transport: BaseTransport):
    """Main bot logic."""
    session_id = str(uuid.uuid4())
    start_time = time.monotonic()
    config = get_session_config(session_id=session_id)
    logger.info(f"Starting bot session_id={session_id} mode={config.get('mode', 'refund')}")

    # Realtime LLM service (handles STT, LLM, and TTS internally).
    # inference_on_context_initialization=False so the counterparty (you) speak first.
    llm = GeminiLiveLLMService(
        api_key=os.getenv("GOOGLE_API_KEY"),
        model=os.getenv("GOOGLE_MODEL"),
        voice_id=os.getenv("GOOGLE_VOICE_ID"),
        system_instruction=config["system_instruction"],
        inference_on_context_initialization=False,
    )

    # Empty initial context so Pipecat sends nothing to Gemini on connect (no first "user" turn).
    # System instruction is already on the LLM service above; no initial response = you speak first, less latency.
    context = LLMContext(messages=[])
    user_aggregator, assistant_aggregator = LLMContextAggregatorPair(
        context,
        user_params=LLMUserAggregatorParams(
            vad_analyzer=SileroVADAnalyzer(params=VADParams(stop_secs=0.2)),
        ),
    )

    pipeline = Pipeline([
        transport.input(),
        user_aggregator,
        llm,
        transport.output(),
        assistant_aggregator,
    ])

    task = PipelineTask(
        pipeline,
        params=PipelineParams(
            enable_metrics=True,
            enable_usage_metrics=True,
        ),
        observers=[],
    )

    @task.rtvi.event_handler("on_client_ready")
    async def on_client_ready(rtvi):
        # Don't queue LLMRunFrame() here — wait for user (counterparty) to speak first
        pass

    @transport.event_handler("on_client_connected")
    async def on_client_connected(transport, client):
        logger.info(f"Client connected session_id={session_id}")

    @transport.event_handler("on_client_disconnected")
    async def on_client_disconnected(transport, client):
        duration_seconds = time.monotonic() - start_time
        logger.info(f"Client disconnected session_id={session_id} duration_secs={round(duration_seconds, 1)}")
        # Brief delay so aggregators can flush in-flight frames into context
        await asyncio.sleep(0.5)
        messages = context.get_messages()
        transcript = _format_transcript(messages)
        transcript_length = len(transcript)
        preview = (transcript[:600] + "…") if len(transcript) > 600 else transcript
        logger.info(
            f"Transcript length={transcript_length} chars session_id={session_id} preview={preview[:120]!r}"
        )
        outcome = await asyncio.to_thread(
            _evaluate_outcome, transcript, config.get("mode", "refund")
        )
        logger.info(f"Auto-evaluated outcome session_id={session_id} outcome={outcome}")
        if os.getenv("WANDB_API_KEY"):
            log_session_end(
                session_id,
                config,
                duration_seconds,
                outcome,
                transcript_length=transcript_length,
                transcript_preview=preview,
            )
        url = os.getenv("REDIS_URL")
        if url and config.get("tactics"):
            r = redis.from_url(url)
            key = f"{REDIS_SESSION_TACTICS_PREFIX}{session_id}{REDIS_SESSION_TACTICS_SUFFIX}"
            r.delete(key)
            r.rpush(key, *config["tactics"])
            r.expire(key, 86400)
            if outcome == "success":
                _merge_winning_tactics(url, session_id, config["tactics"])
                suggested = await asyncio.to_thread(
                    _suggest_new_tactic, transcript, config.get("mode", "refund")
                )
                if suggested:
                    base_raw = r.lrange(REDIS_TACTICS_KEY, 0, -1) or []
                    base_set = {b.decode() if isinstance(b, bytes) else b for b in base_raw}
                    winning_raw = r.lrange(REDIS_WINNING_KEY, 0, -1) or []
                    winning_set = {b.decode() if isinstance(b, bytes) else b for b in winning_raw}
                    if suggested not in base_set and suggested not in winning_set:
                        r.rpush(REDIS_WINNING_KEY, suggested)
                        logger.info(f"Suggested new tactic (session_id={session_id}): {suggested[:80]}...")
            else:
                base_raw = r.lrange(REDIS_TACTICS_KEY, 0, -1) or []
                base_tactics = {b.decode() if isinstance(b, bytes) else b for b in base_raw}
                existing_raw = r.lrange(REDIS_FAILED_KEY, 0, -1) or []
                existing = {e.decode() if isinstance(e, bytes) else e for e in existing_raw}
                for t in config["tactics"]:
                    if t not in base_tactics and t not in existing:
                        r.rpush(REDIS_FAILED_KEY, t)
                        existing.add(t)
                r.expire(REDIS_FAILED_KEY, 86400 * 7)
            r.close()
        await task.cancel()




    runner = PipelineRunner(handle_sigint=False)

    await runner.run(task)


async def bot(runner_args: RunnerArguments):
    """Main bot entry point."""
    transport = None

    match runner_args:
        case SmallWebRTCRunnerArguments():
            webrtc_connection: SmallWebRTCConnection = runner_args.webrtc_connection

            transport = SmallWebRTCTransport(
                webrtc_connection=webrtc_connection,
                params=TransportParams(
                    audio_in_enabled=True,
                    audio_out_enabled=True,
                ),
            )
        case _:
            logger.error(f"Unsupported runner arguments type: {type(runner_args)}")
            return

    await run_bot(transport)


if __name__ == "__main__":
    from pipecat.runner.run import main

    main()